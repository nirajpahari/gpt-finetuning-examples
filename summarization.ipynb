{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "Dataset: [Amazon fine food reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 21:28:16.832878: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-11 21:28:16.871835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 21:28:17.601579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to cuda if available\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device=\"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/summarization/Reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file into pandas df\n",
    "reviews_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all the columns in the df\n",
    "reviews_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we only need Summary and Text keep only these columns and drop remaining columns\n",
    "reviews_df = reviews_df[['Summary', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Summary  568427 non-null  object\n",
      " 1   Text     568454 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check df info\n",
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values and duplicates if any\n",
    "reviews_df = reviews_df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 394967 entries, 0 to 568453\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Summary  394967 non-null  object\n",
      " 1   Text     394967 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Summary                                               Text\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
       "4            Great taffy  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe now contains summary and text.\n",
    "Now, we create a new column such that it contains `<<text>>, TL;DR <<summary>>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['data'] = reviews_df['Text'] + ', TL;DR ' + reviews_df['Summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Quality Dog Food\n",
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most., TL;DR Good Quality Dog Food\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.iloc[0]['Summary'])\n",
    "print(reviews_df.iloc[0]['Text'])\n",
    "print(reviews_df.iloc[0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not as Advertised\n",
      "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
      "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\"., TL;DR Not as Advertised\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.iloc[1]['Summary'])\n",
    "print(reviews_df.iloc[1]['Text'])\n",
    "print(reviews_df.iloc[1]['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hop/home/pahari_niraj/Projects/.env/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:1177: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelWithLMHead.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save the finetuned model\n",
    "model_path = './output/summarization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to gpu for processing in gpu\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer for training\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Max length to cover all the examples\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_length = len(tokenizer.encode(\" TL;DR \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenizer, reviews, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eos = self.tokenizer.eos_token\n",
    "        self.eos_id = self.tokenizer.eos_token_id\n",
    "        self.reviews = reviews\n",
    "        self.result = []\n",
    "\n",
    "        for review in self.reviews:\n",
    "            # Encode the text using the tokenizer\n",
    "            tokenized = self.tokenizer.encode(review + self.eos)\n",
    "\n",
    "            # padding the encoded sequence to max_len\n",
    "            padded = self.pad_truncate(tokenized)\n",
    "\n",
    "            # Creating a tensor and adding  to the result\n",
    "            self.result.append(torch.tensor(padded))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.result)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.result[item]\n",
    "    \n",
    "    def pad_truncate(self, tokenized):\n",
    "        tokenized_length = len(tokenized) - extra_length\n",
    "        if tokenized_length < self.max_len:\n",
    "            difference = self.max_len - tokenized_length\n",
    "            padded = tokenized + [self.eos_id] * difference\n",
    "        elif tokenized_length > self.max_len:\n",
    "            padded = tokenized[:self.max_len + 3]+[self.eos_id]\n",
    "        else:\n",
    "            padded = tokenized\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1601973/2455563057.py:3: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  reviews=reviews_df['data'][:10000],\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Load data into this custom dataset\n",
    "dataset = CustomDataset(tokenizer=tokenizer,\n",
    "                        reviews=reviews_df['data'][:10000],\n",
    "                        max_len=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   40,   423,  5839,  1811,   286,   262, 28476,   414, 32530,  3290,\n",
       "         2057,  3186,   290,   423,  1043,   606,   477,   284,   307,   286,\n",
       "          922,  3081,    13,   383,  1720,  3073,   517,   588,   257, 20798,\n",
       "          621,   257, 13686,  6174,   290,   340, 25760,  1365,    13,  2011,\n",
       "        45246,   318,   957, 17479,   290,   673,  5763,   689,   428,  1720,\n",
       "         1365,   621,   220,   749,  1539, 24811,    26,  7707,  4599, 14156,\n",
       "         8532,  7318, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a object in dataset class\n",
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(model, optimizer, dl, epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for idx, batch in enumerate(dl):\n",
    "            optimizer.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = output[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if idx%100 == 0:\n",
    "                print(f\"Loss: {loss}, Batches: {idx}\")\n",
    "                model.save_pretrained(model_path)\n",
    "                # torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.325080871582031, Batches: 0\n",
      "Loss: 1.5559827089309692, Batches: 100\n",
      "Loss: 1.6936368942260742, Batches: 200\n",
      "Loss: 1.4153869152069092, Batches: 300\n"
     ]
    }
   ],
   "source": [
    "fine_tune(model=model, optimizer=optimizer, dl=dataloader, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topk implementation for selecting from topk choices\n",
    "def topk(probs, n=9):\n",
    "    # Convert the scores using softmax to probabilities\n",
    "    probs = torch.softmax(probs, dim=-1)\n",
    "\n",
    "    # Use topk implemntation provided by pytorch\n",
    "    tokens_prob, topix = torch.topk(probs, k=n)\n",
    "\n",
    "    # the new selection pool is normalized\n",
    "    tokens_prob = tokens_prob / torch.sum(tokens_prob)\n",
    "\n",
    "    # To CPU for handling by numpy\n",
    "    tokens_prob = tokens_prob.cpu().detach().numpy()\n",
    "\n",
    "    # Randomly select from the pool of prob distribution\n",
    "    choice = np.random.choice(n, 1, p = tokens_prob)\n",
    "    token_id = topix[choice][0]\n",
    "\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, tokenizer, review, max_length=15):\n",
    "    # Preprocess the initial tokens\n",
    "    review_encoded = tokenizer.encode(review)\n",
    "    result = review_encoded\n",
    "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    # Feed the initial input to the model\n",
    "    output = model(initial_input)\n",
    "\n",
    "    # Flatten the logits at the final time step\n",
    "    logits = output.logits[0, -1]\n",
    "\n",
    "    # Make a top-k choice and append to the result\n",
    "    result.append(topk(logits))\n",
    "\n",
    "    # For max_length times\n",
    "    for _ in range(max_length):\n",
    "        # Feed the current updated sequence to the model and make a choice\n",
    "        input = torch.tensor(result).unsqueeze(0).to(device)\n",
    "        output = model(input)\n",
    "        logits = output.logits[0,-1]\n",
    "        res_id = topk(logits)\n",
    "\n",
    "        # If EOS is encountered return the result\n",
    "        if res_id == tokenizer.eos_token_id:\n",
    "            return tokenizer.decode(result)\n",
    "        else:\n",
    "            # Append the token to the sequence\n",
    "            result.append(res_id)\n",
    "\n",
    "    # IF max_length is encountered\n",
    "    return tokenizer.decode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(model_path))\n",
    "model = model.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = \"\"\"My local coffee shop has me addicted to their 20 oz vanilla chai lattes. \n",
    "                At $3.90 a pop I was spending a lot of money.  I asked what brand they used,\n",
    "                need nutritional information, of course!  They told me it was Big Train Chai Vanilla.\n",
    "                <br />It's important to follow the directions on the can.  I made mine with just milk\n",
    "                  with a yucky result.  Use the water with a little milk as there is milk powder in the \n",
    "                  mix.<br /><br />WARNING:It's addicting!!!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model_inference(model, tokenizer, test_review + \" TL;DR \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        <br />I'm addicted to the flavor\n"
     ]
    }
   ],
   "source": [
    "print(summary.split(' TL;DR ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
